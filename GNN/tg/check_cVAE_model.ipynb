{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "import pickle\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "\n",
    "from tg_GNNcVAE import GraphcVAE\n",
    "from tg_Preprocessing import load_tg_data\n",
    "from tg_config import tg_clf_config"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "epochs = tg_clf_config['epochs']\n",
    "learning_rate = tg_clf_config['learning_rate']\n",
    "CUDA = tg_clf_config['CUDA']\n",
    "log_step = tg_clf_config['log_step']\n",
    "save_step = tg_clf_config['save_step']\n",
    "TRAIN = tg_clf_config['TRAIN']\n",
    "plot_mAP = tg_clf_config['plot_mAP']\n",
    "probability_threshold = tg_clf_config['probability_threshold']\n",
    "model_path = tg_clf_config['model_path']\n",
    "batch_size = tg_clf_config['batch_size']\n",
    "n_encoding_feature = tg_clf_config['n_encoding_feature']\n",
    "in_node = tg_clf_config['in_node']\n",
    "data_size = tg_clf_config['tg_clf_config']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "train_set:list = []\n",
    "val_set:list = []\n",
    "test_set:list = []\n",
    "for i in range(data_size[0],data_size[1]):\n",
    "    tmp_train_set, tmp_val_set, tmp_test_set = load_tg_data(num=i)\n",
    "    train_set += tmp_train_set\n",
    "    val_set += tmp_val_set\n",
    "    test_set += tmp_test_set"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "GNN_cVAE = GraphcVAE(\n",
    "     en_graph_in_channels=17338, en_graph_hidden_channels=256, en_graph_num_layers=1, en_graph_out_channels=128,\n",
    "     hidden_channels=128, num_layers=1, z_dim=32,\n",
    "     de_graph_in_channels=17338, de_graph_hidden_channels=256, de_graph_num_layers=1, de_graph_out_channels=256,\n",
    "     num_z_layers=2,\n",
    "     clf_num_layers=3,\n",
    "     dropout=0.0, act=nn.ReLU(), graph_linear_num_layers=4)# clf_model.apply(init_weights)\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "if CUDA:\n",
    "    GNN_cVAE.cuda()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "GNN_cVAE.load_state_dict(torch.load('./save_model/tg_GNN_cVAE_2021-09-28_08-22.pt'))\n",
    "GNN_cVAE.eval()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GraphcVAE(\n",
       "  (encoder): Encoder(\n",
       "    (GraphEncoding): GraphSAGE(17338, 256, num_layers=1)\n",
       "    (LinearEncoding): ModuleList(\n",
       "      (0): Linear(256, 256, bias=True)\n",
       "      (1): Linear(256, 256, bias=True)\n",
       "      (2): Linear(256, 256, bias=True)\n",
       "      (3): Linear(256, 256, bias=True)\n",
       "      (4): Linear(256, 128, bias=True)\n",
       "    )\n",
       "    (activation): ELU(alpha=1.0)\n",
       "    (TotalLinearEncoding): ModuleList(\n",
       "      (0): Linear(129, 128, bias=True)\n",
       "      (1): Linear(128, 128, bias=True)\n",
       "      (2): Linear(128, 64, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (z_layers): ModuleList(\n",
       "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    )\n",
       "    (GraphEncoding): GraphSAGE(17338, 256, num_layers=1)\n",
       "    (clf_layers): ModuleList(\n",
       "      (0): Linear(288, 256, bias=True)\n",
       "      (1): Linear(256, 256, bias=True)\n",
       "      (2): Linear(256, 256, bias=True)\n",
       "      (3): Linear(256, 256, bias=True)\n",
       "      (4): Linear(256, 1, bias=True)\n",
       "    )\n",
       "    (sigmoid): Sigmoid()\n",
       "    (activation): ELU(alpha=1.0)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "z = torch.randn(32)\n",
    "z"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([ 1.0953,  0.0853,  0.3722,  0.7187,  1.1736,  0.5100, -0.0611,  0.7975,\n",
       "         0.3343,  0.3685, -0.0359,  0.7883,  1.7624,  0.1117,  0.7646,  0.0204,\n",
       "        -0.7119, -0.5214,  1.0306, -1.5767, -0.1559, -0.7975, -1.1704, -1.8236,\n",
       "        -0.0195,  1.1334, -1.7669, -2.5623, -0.2870,  0.9759,  0.9001, -1.2198])"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "z = z.cuda()\n",
    "for _ in range(10):\n",
    "    index = random.randint(0,len(train_set))\n",
    "    print(index)\n",
    "    data = train_set[index]\n",
    "    data = data.cuda()\n",
    "    l = GNN_cVAE.decoder(data.x, data.edge_index, z)\n",
    "    print(l.view(-1))\n",
    "    print(data.y)\n",
    "    print()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "289\n",
      "tensor([0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689,\n",
      "        0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689,\n",
      "        0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1.], device='cuda:0')\n",
      "\n",
      "982\n",
      "tensor([0.2689, 0.2689, 0.2689, 0.3276, 0.2689, 0.2689, 0.2689, 0.9817, 0.2689,\n",
      "        0.2730, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689,\n",
      "        0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.9959],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1.], device='cuda:0')\n",
      "\n",
      "1214\n",
      "tensor([0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2695,\n",
      "        0.2689, 0.2689, 0.2689, 0.9952, 0.2689, 0.2689, 0.2689, 0.9960, 0.2689,\n",
      "        0.2693, 0.9351, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        1., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "\n",
      "2061\n",
      "tensor([0.9811, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689,\n",
      "        0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.9961, 0.2689, 0.2689, 0.9966,\n",
      "        0.2702, 0.9940, 0.2758, 0.2689, 0.2689, 0.2689, 0.9852],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 1.], device='cuda:0')\n",
      "\n",
      "663\n",
      "tensor([0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689,\n",
      "        0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689,\n",
      "        0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "\n",
      "1654\n",
      "tensor([0.2690, 0.2689, 0.2689, 0.2689, 0.2689, 0.9293, 0.9863, 0.2689, 0.2689,\n",
      "        0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689,\n",
      "        0.2689, 0.2689, 0.2689, 0.2689, 0.9673, 0.2689, 0.2689],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0.], device='cuda:0')\n",
      "\n",
      "1921\n",
      "tensor([0.2689, 0.2689, 0.2689, 0.2690, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689,\n",
      "        0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2691,\n",
      "        0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 0.], device='cuda:0')\n",
      "\n",
      "1318\n",
      "tensor([0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.9817, 0.2689, 0.2834, 0.2689,\n",
      "        0.2689, 0.2694, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689,\n",
      "        0.2689, 0.2689, 0.2689, 0.2689, 0.9832, 0.2689, 0.2689],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0.], device='cuda:0')\n",
      "\n",
      "1252\n",
      "tensor([0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2691, 0.2689, 0.2689, 0.2689,\n",
      "        0.2689, 0.2689, 0.2689, 0.2689, 0.2690, 0.2689, 0.2689, 0.2690, 0.2689,\n",
      "        0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 1., 0.], device='cuda:0')\n",
      "\n",
      "1193\n",
      "tensor([0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689,\n",
      "        0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689,\n",
      "        0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689, 0.2689],\n",
      "       device='cuda:0', grad_fn=<ViewBackward>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0.], device='cuda:0')\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('torch_geometric': conda)"
  },
  "interpreter": {
   "hash": "b45ff344b65373c57fc2cdeb2147a162c393ddcbf9969e6858f3f88fd483cb41"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}